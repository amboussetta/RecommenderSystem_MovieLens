---
title: "MovieLens Capstone"
author: "Mohammed Amine BOUSSETTA"
date: "08/04/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(dplyr)
library(tidyverse)
library(lubridate)
library("e1071")
library("genefilter")
library(dslabs)
library(rpart)
library(rpart.plot)
library(randomForest)
library(Rborist)
library(purrr)
library(Metrics)
library(RColorBrewer)
library(matrixStats)
library(stringr)
```

# Introduction
The capstone project in the data science series of Harvardx is about creating a recommander system based on the Movielens dataset and will be evaluated using the root mean squared error metric. As defined by Wikipedia, a recommender system is a subclass of information filtering system that seeks to predict the "rating" or "preference" a user would give to an item. Those systems are used in many areas such as social networking, online markets, search queries, financial services and so many others... Our project focuses on using this system to predict a user's rating of a certain movie.

One of the events that energized research in recommender systems was the Netflix Prize. The company offered a 1M $ prize to the team who can build a recommander system 10% more accurate than those offered by Netflix at the time. On 21 September 2009, the prize was announced and was given to BellKor's Pragmatic Chaos team.

The MovieLens data sets were collected by the GroupLens Research Project at the University of Minnesota. Each user has rated at least 20 movies. The data was collected through the MovieLens web site (movielens.umn.edu) during the seven-month period from September 19th, 1997 through April 22nd, 1998. In this project, we will be working with the 10M version of the data set which contains 10 million ratings and 100,000 tag applications applied to 10,000 movies by 72,000 users. 

This report will be structured in three parts: the first one will be dedicated to getting the data ready to be cleaned, explored and analysed to get first thoughts about feature engineering and models to be chosen. The next part will cover the modeling approches used and their impact on the rmse results. The last part will discuss further approches to be tested in order to improve the scores.

# Data exploration and analysis

## 1- Prepare the data 

This piece of code was provided by edX to download the dataset and reorganise it into two data frames ("edx", "validation") contianing the movie ID, the user ID, the rating and the timestamp variables.

```{r}
# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- read.table(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                      col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data

set.seed(1)
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set

validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set

removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

Let's see now how the data looks like:

```{r}
head(edx)
```

The dataset contains 'r nrow(edx)' and 'r ncol(edx)' variables:

- `userId`: Unique identification number for each user. `numeric` variable  
- `movieId`: Unique identification number for each movie. `numeric` variable.  
- `timestamp`: Code representing the date and time when a user rated a movie. `integer` variable.  
- `title`: Title of the movie. `character` variable.  
- `genres`: Motion-picture category associated to the film. `character` variable.  
- `rating`: Rating given by the user to the movie. From 0 to 5 *stars* in steps of 0.5. `numeric` variable. 

## 2- Processing the data

Let's first check the type of our variables and see if they need to be converted in other types to facilitate the modeling part or simply make the executions easier:

```{r}
sapply(edx, class)
```

We remark that the userID and the movieID variables are not ordinal i.e. there is no order in the IDs and comparing movie number 623 with movie number 28 doesn't make sense. However, it does when comparing timestamps and ratings. We could then make the IDs as factors because this type is super useful in summary statistics.

The timestamp variable also must be converted to a more understandable number to use it in our analysis. The provided code can be converted to a date-time format then we can extract any time period. Let's go with the year for now.

Then, we can extract two useful variables which are the rating year and the release year. We can use those two variables for example to calculate the age of a certain movie when the rating was done by a user.

```{r}
edx$userId <- as.factor(edx$userId) 
edx$movieId <- as.factor(edx$movieId) 
edx$genres <- as.factor(edx$genres) 
edx$timestamp <- as.POSIXct(edx$timestamp, origin = "1970-01-01")

edx <- edx %>% 
  mutate(title = str_trim(title), year_rate = year(timestamp)) %>%
  extract(title, c("title_tmp", "year"),
          regex = "^(.*) \\(([0-9 \\-]*)\\)$",
          remove = F) %>%
  mutate(year = if_else(str_length(year) > 4,
                        as.integer(str_split(year, "-",
                                             simplify = T)[1]),
                        as.integer(year))) %>%
  mutate(title = if_else(is.na(title_tmp), title, title_tmp)) %>%
  select(-title_tmp)  %>%
  mutate(genres = if_else(genres == "(no genres listed)",
                          `is.na<-`(genres), genres)) %>% 
    select(-title, -timestamp)
```
Now our dataset looks like this:

```{r}
head(edx)
```
We could check if the integer values year, year_rate and rating have no outliers by running a summary and we find that there are none ( No rating outside the 0-5 range, no year outside 1915-2009!

```{r}
numvectors <- data.frame(edx$rating,edx$year, edx$year_rate)
summary(numvectors)
```

## 3- Exploring the data
### 3-1 Summary statistics on the dataset

First, let's see how many observations, unique users, unique movies and genres we are dealing with:

```{r}
# number of observations and variables:
dim(edx)
#number of uniques users
n_distinct(edx$userId)
# number of uniques movies
n_distinct(edx$movieId)
# number of distinct genres| genres can be a combination of many so we split them to count:
n_distinct(edx %>% separate_rows(genres, sep= "\\|") %>% select(genres))
```

### 3-2 Discovering the data distribution

Since our objective is to predict the ratings, let's first draw a histogram of the ratings:

```{r}
edx %>% ggplot(aes(x=rating)) + geom_histogram(binwidth=0.5, colour="blue", 
                                              aes(y=..density.., fill=..count..)) +
                      scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C") +
                      stat_function(fun=dnorm, color="red",args=list(mean, stdv))
                         
```
 The distribution is not really normal shaped and we see a negative skewness. There is also no rating with the value 0 and most of the ratings comes exactly at 3 and 4. Why there are more good ratings than bad ones? This could be explained by the fact that when a user watch a movie and like it, he finds the time to rate this movie. But when a user does not like a movie, he simply doesn't bother and pass.
 
 Now let's see how the number of ratings evolve with the release year of the movies:
 
```{r}
edx %>% ggplot(aes(year)) +
  geom_histogram(fill = "black") +
  labs(title = "Frequency of ratings by relase year",
       x = "Year",
       y = "Frequency")
```
 
Again we have a left skewed distribution with most of the ratings happening between 1980 and 2009. Now let's introduce the age variable and see its distribution:

```{r}
edx <- edx %>% mutate(age = year_rate - year)

plot1 <- edx %>% ggplot(aes(age)) +
  geom_histogram(binwidth = 5, fill = "black") +
  labs(title = "Frequency of ratings by age of the movie",
       x = "Age",
       y = "Frequency")

plot2 <- edx %>% 
  group_by(age) %>% 
  summarize(b_a = mean(rating)) %>% 
  ggplot(aes(b_a)) + 
  geom_histogram(color = "darkblue") +
  ggtitle("Mean rating by age of the movie")

grid.arrange(plot1, plot2, ncol=2)
```

The histogram explains that recent movies are rated more enough than older ones. This can be explained by the fact that people tend to watch popular movies and searching for new movies each time. People are usually not very interested in old movies because either they have watched many mavies before they started ratings movies or no one in their social network recommands an old movie.

Now let's see if the users and the movies have some effect on the ratings:
```{r}
plot1 <- edx %>% 
dplyr::count(userId) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() + 
  ggtitle("Rating count by users")
plot2 <- edx %>% 
  group_by(userId) %>% 
  summarize(b_u = mean(rating)) %>% 
  filter(n()>=100) %>%
  ggplot(aes(b_u)) + 
  geom_histogram(bins = 30, color = "darkblue") +
  ggtitle("Mean rating by users")
plot3 <- edx %>% 
  dplyr::count(movieId) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() + 
  ggtitle("Rating count by movies")
plot4 <- edx %>% 
  group_by(userId) %>% 
  summarize(b_m = mean(rating)) %>% 
  filter(n()>=100) %>%
  ggplot(aes(b_m)) + 
  geom_histogram(bins = 30, color = "darkblue") +
  ggtitle("Mean rating by movies")
grid.arrange(plot1, plot2, plot3, plot4, ncol=2, nrow=2)
```
Let's discuss the first row of the facet plot: we see that some users are more active than others, some users are very cranky and others love every movie. The same analysis applies form movies: some movies are rated and appreciated more than others. This makes the variables users, movies and age have a strong impact on the ratings.

Finally, let's print the genres and their corresponding average rating by descending order to introduce a technique that will be relevant in our modeling:

```{r}
edx %>%
  select(genres, rating) %>%
  group_by(genres) %>%
  summarize(mean = mean(rating), median = median(rating), n = n()) %>%
  arrange(desc(mean)) %>%
  head(10)
```

In this table, the genre "Animation|IMAX|Sci-Fi" has the highest mean and median rating but this is not significant because it only has 7 ratings. To deal with this problem, we introduce regularization which permits us to penalize large estimates that are formed using small sample sizes.